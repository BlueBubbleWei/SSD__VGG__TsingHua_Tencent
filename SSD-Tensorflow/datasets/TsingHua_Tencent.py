import tensorflow as tf
from datasets import pascalvoc_common
slim = tf.contrib.slim
FILE_PATTERN = 'TsingHua_Tencent_%s_*.tfrecord'
# FILE_PATTERN = 'voc_2012_%s_*.tfrecord'
ITEMS_TO_DESCRIPTIONS = {
    'image': 'A color image of varying height and width.',
    'shape': 'Shape of the image',
    'object/bbox': 'A list of bounding boxes, one per each object.',
    'object/label': 'A list of labels, one per each object.',
}
# (Images, Objects) statistics on every class.
TRAIN_STATISTICS = {'i1': (1, 1),
                   'i10': (2, 2),
                   'i11': (3, 3),
                   'i12': (4, 4),
                   'i13': (5, 5),
                   'i14': (6, 6),
                   'i15': (7, 7),
                   'i2': (8, 8),
                   'i3': (9, 9),
                   'i4': (10, 10),
                   'i5': (11, 11),
                   'il100': (12, 12),
                   'il110': (13, 13),
                   'il50': (14, 14),
                   'il60': (15, 15),
                   'il70': (16, 16),
                   'il80': (17, 17),
                   'il90': (18, 18),
                   'io': (19, 19),
                   'ip': (20, 20),
                   'p1': (21, 21),
                   'p10': (22, 22),
                   'p11': (23, 23),
                   'p12': (24, 24),
                   'p13': (25, 25),
                   'p14': (26, 26),
                   'p15': (27, 27),
                   'p16': (28, 28),
                   'p17': (29, 29),
                   'p18': (30, 30),
                   'p19': (31, 31),
                   'p2': (32, 32), 'p20': (33, 33), 'p21': (34, 34), 'p22': (35, 35), 'p23': (36, 36), 'p24': (37, 37), 'p25': (38, 38), 'p26': (39, 39), 'p27': (40, 40), 'p28': (41, 41), 'p3': (42, 42), 'p4': (43, 43), 'p5': (44, 44), 'p6': (45, 45), 'p7': (46, 46), 'p8': (47, 47), 'p9': (48, 48), 'pa10': (49, 49), 'pa12': (50, 50), 'pa13': (51, 51), 'pa14': (52, 52), 'pa8': (53, 53), 'pb': (54, 54), 'pc': (55, 55), 'pg': (56, 56), 'ph1.5': (57, 57), 'ph2': (58, 58), 'ph2.1': (59, 59), 'ph2.2': (60, 60), 'ph2.4': (61, 61), 'ph2.5': (62, 62), 'ph2.8': (63, 63), 'ph2.9': (64, 64), 'ph3': (65, 65), 'ph3.2': (66, 66), 'ph3.5': (67, 67), 'ph3.8': (68, 68), 'ph4': (69, 69), 'ph4.2': (70, 70), 'ph4.3': (71, 71), 'ph4.5': (72, 72), 'ph4.8': (73, 73), 'ph5': (74, 74), 'ph5.3': (75, 75), 'ph5.5': (76, 76), 'pl10': (77, 77), 'pl100': (78, 78), 'pl110': (79, 79), 'pl120': (80, 80), 'pl15': (81, 81), 'pl20': (82, 82), 'pl25': (83, 83), 'pl30': (84, 84), 'pl35': (85, 85), 'pl40': (86, 86), 'pl5': (87, 87), 'pl50': (88, 88), 'pl60': (89, 89), 'pl65': (90, 90), 'pl70': (91, 91), 'pl80': (92, 92), 'pl90': (93, 93), 'pm10': (94, 94), 'pm13': (95, 95), 'pm15': (96, 96), 'pm1.5': (97, 97), 'pm2': (98, 98), 'pm20': (99, 99), 'pm25': (100, 100), 'pm30': (101, 101), 'pm35': (102, 102), 'pm40': (103, 103), 'pm46': (104, 104), 'pm5': (105, 105), 'pm50': (106, 106), 'pm55': (107, 107), 'pm8': (108, 108), 'pn': (109, 109), 'pne': (110, 110), 'po': (111, 111), 'pr10': (112, 112), 'pr100': (113, 113), 'pr20': (114, 114), 'pr30': (115, 115), 'pr40': (116, 116), 'pr45': (117, 117), 'pr50': (118, 118), 'pr60': (119, 119), 'pr70': (120, 120), 'pr80': (121, 121), 'ps': (122, 122), 'pw2': (123, 123), 'pw2.5': (124, 124), 'pw3': (125, 125), 'pw3.2': (126, 126), 'pw3.5': (127, 127), 'pw4': (128, 128), 'pw4.2': (129, 129), 'pw4.5': (130, 130), 'w1': (131, 131), 'w10': (132, 132), 'w12': (133, 133), 'w13': (134, 134), 'w16': (135, 135), 'w18': (136, 136), 'w20': (137, 137), 'w21': (138, 138), 'w22': (139, 139), 'w24': (140, 140), 'w28': (141, 141), 'w3': (142, 142), 'w30': (143, 143), 'w31': (144, 144), 'w32': (145, 145), 'w34': (146, 146), 'w35': (147, 147), 'w37': (148, 148), 'w38': (149, 149), 'w41': (150, 150), 'w42': (151, 151), 'w43': (152, 152), 'w44': (153, 153), 'w45': (154, 154), 'w46': (155, 155), 'w47': (156, 156), 'w48': (157, 157), 'w49': (158, 158), 'w5': (159, 159), 'w50': (160, 160), 'w55': (161, 161), 'w56': (162, 162), 'w57': (163, 163), 'w58': (164, 164), 'w59': (165, 165), 'w60': (166, 166), 'w62': (167, 167), 'w63': (168, 168), 'w66': (169, 169), 'w8': (170, 170), 'wo': (171, 171), 'i6': (172, 172), 'i7': (173, 173), 'i8': (174, 174), 'i9': (175, 175), 'ilx': (176, 176), 'p29': (177, 177), 'w29': (178, 178), 'w33': (179, 179), 'w36': (180, 180), 'w39': (181, 181), 'w4': (182, 182), 'w40': (183, 183), 'w51': (184, 184), 'w52': (185, 185), 'w53': (186, 186), 'w54': (187, 187), 'w6': (188, 188), 'w61': (189, 189), 'w64': (190, 190), 'w65': (191, 191), 'w67': (192, 192), 'w7': (193, 193), 'w9': (194, 194), 'pax': (195, 195), 'pd': (196, 196), 'pe': (197, 197), 'phx': (198, 198), 'plx': (199, 199), 'pmx': (200, 200), 'pnl': (201, 201), 'prx': (202, 202), 'pwx': (203, 203), 'w11': (204, 204), 'w14': (205, 205), 'w15': (206, 206), 'w17': (207, 207), 'w19': (208, 208), 'w2': (209, 209), 'w23': (210, 210), 'w25': (211, 211), 'w26': (212, 212), 'w27': (213, 213), 'pl0': (214, 214), 'pl4': (215, 215), 'pl3': (216, 216), 'pm2.5': (217, 217), 'ph4.4': (218, 218), 'pn40': (219, 219), 'ph3.3': (220, 220), 'ph2.6': (221, 221), 'None': 0}

SPLITS_TO_SIZES = {
    'train': 17125,
}
SPLITS_TO_STATISTICS = {
    'train': TRAIN_STATISTICS,
}
NUM_CLASSES = 20


def get_split(split_name, dataset_dir, file_pattern=None, reader=None):
    """Gets a dataset tuple with instructions for reading ImageNet.

    Args:
      split_name: A train/test split name.
      dataset_dir: The base directory of the dataset sources.
      file_pattern: The file pattern to use when matching the dataset sources.
        It is assumed that the pattern contains a '%s' string so that the split
        name can be inserted.
      reader: The TensorFlow reader type.

    Returns:
      A `Dataset` namedtuple.

    Raises:
        ValueError: if `split_name` is not a valid train/test split.
    """
    if not file_pattern:
        file_pattern = FILE_PATTERN
    return pascalvoc_common.get_split(split_name, dataset_dir,
                                      file_pattern, reader,
                                      SPLITS_TO_SIZES,
                                      ITEMS_TO_DESCRIPTIONS,
                                      NUM_CLASSES)