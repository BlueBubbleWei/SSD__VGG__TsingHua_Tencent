{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiyumei/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Replicating the `model_fn` across ['/device:CPU:0'].  Variables are going to be placed on ['/CPU:0'].  Consolidation device is going to be /CPU:0.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'logs', '_tf_random_seed': 20180823, '_save_summary_steps': 500, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 7200, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f99f6a2edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Starting a training cycle.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /mnt/Data/weiyumei/deeplearning/finalwork/ssd_net.py:114: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiyumei/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& ./model\n",
      "INFO:tensorflow:Fine-tuning from None. Ignoring missing vars: True.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f97cfa231563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-f97cfa231563>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting a training cycle.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     ssd_detector.train(input_fn=input_pipeline(dataset_pattern='train-*', is_training=True, batch_size=batch_size),\n\u001b[0;32m--> 385\u001b[0;31m                     hooks=[logging_hook], max_steps=max_number_of_steps)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 856\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    857\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m    858\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py\u001b[0m in \u001b[0;36msingle_device_model_fn\u001b[0;34m(features, labels, mode, params, config)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         local_ps_devices=ps_devices)[0]  # One device, so one spec is out.\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreplicated_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py\u001b[0m in \u001b[0;36m_get_loss_towers\u001b[0;34m(model_fn, mode, features, labels, params, config, devices, local_ps_devices, loss_reduction, name_scope_pattern)\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_shard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                 **optional_params)\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             if (tower_spec.train_op is not None and len(devices) > 1 and\n",
      "\u001b[0;32m<ipython-input-1-f97cfa231563>\u001b[0m in \u001b[0;36mssd_model_fn\u001b[0;34m(features, labels, mode, params)\u001b[0m\n\u001b[1;32m    326\u001b[0m                               \u001b[0mtrain_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                               \u001b[0meval_metric_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                               scaffold=tf.train.Scaffold(init_fn=get_init_fn()))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_comma_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-f97cfa231563>\u001b[0m in \u001b[0;36mget_init_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m                                             \u001b[0mmodel_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_model_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                                             \u001b[0mcheckpoint_exclude_scopes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                                             name_remap={'/kernel': '/weights', '/bias': '/biases'})\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# couldn't find better way to pass params from input_fn to model_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Data/weiyumei/deeplearning/finalwork/utility/scaffolds.py\u001b[0m in \u001b[0;36mget_init_fn_for_scaffold\u001b[0;34m(model_dir, checkpoint_path, model_scope, checkpoint_model_scope, checkpoint_exclude_scopes, ignore_missing_vars, name_remap)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variables_to_restore cannot be empty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mignore_missing_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_to_restore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mvar_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables_to_restore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_api_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train.NewCheckpointReader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 67\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got None"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ssd_net\n",
    "\n",
    "from dataset import dataset_common\n",
    "from preprocessing import ssd_preprocessing\n",
    "from utility import anchor_manipulator\n",
    "from utility import scaffolds\n",
    "import Basic\n",
    "\n",
    "batch_size=32\n",
    "train_epochs=8\n",
    "num_readers=8\n",
    "num_preprocessing_threads=24\n",
    "data_dir=Basic.DATADIR+'/Tfrecords'\n",
    "model_dir='logs'\n",
    "checkpoint_path='./model'\n",
    "checkpoint_model_scope= 'vgg_16'\n",
    "checkpoint_exclude_scopes='ssd300/multibox_head, ssd300/additional_layers, ssd300/conv4_3_scale'\n",
    "ignore_missing_vars=True\n",
    "train_image_size=300\n",
    "gpu_memory_fraction=1.0\n",
    "num_cpu_threads=0\n",
    "save_checkpoints_secs=7200\n",
    "save_summary_steps=500\n",
    "tf_random_seed=20180823\n",
    "log_every_n_steps=10\n",
    "data_format='channels_first'\n",
    "model_scope='ssd300'\n",
    "num_classes=21\n",
    "negative_ratio=3.0\n",
    "match_threshold=0.5\n",
    "neg_threshold=0.5\n",
    "weight_decay=5e-4\n",
    "momentum=0.9\n",
    "learning_rate=1e-3\n",
    "end_learning_rate=0.000001\n",
    "decay_boundaries='500, 80000, 100000'\n",
    "lr_decay_factors='0.1, 1, 0.1, 0.01'\n",
    "log_every_n_steps=10\n",
    "max_number_of_steps=120000 \n",
    "multi_gpu=False\n",
    "\n",
    "\n",
    "\n",
    "#CUDA_VISIBLE_DEVICES\n",
    "def validate_batch_size_for_multi_gpu(batch_size):\n",
    "    \"\"\"\n",
    "    For multi-gpu,批量大小必须是数量的倍数可用的GPU。\n",
    "     请注意，这最终应由replicate_model_fn处理\n",
    "    \"\"\"\n",
    "    if multi_gpu:\n",
    "        from tensorflow.python.client import device_lib\n",
    "\n",
    "        local_device_protos = device_lib.list_local_devices()\n",
    "        print('local_device_protos :',local_device_protos )\n",
    "        num_gpus = sum([1 for d in local_device_protos if d.device_type == 'GPU'])\n",
    "        if not num_gpus:\n",
    "            raise ValueError('Multi-GPU mode was specified, but no GPUs '\n",
    "                            'were found. To use CPU, run --multi_gpu=False.')\n",
    "\n",
    "        remainder = batch_size % num_gpus\n",
    "        if remainder:\n",
    "            err = ('When running with multiple GPUs, batch size '\n",
    "                    'must be a multiple of the number of available GPUs. '\n",
    "                    'Found {} GPUs with a batch size of {}; try --batch_size={} instead.'\n",
    "                    ).format(num_gpus, batch_size, batch_size - remainder)\n",
    "            raise ValueError(err)\n",
    "        return num_gpus\n",
    "    return 0\n",
    "\n",
    "def get_init_fn():\n",
    "    return scaffolds.get_init_fn_for_scaffold(model_dir, checkpoint_path,\n",
    "                                            model_scope, checkpoint_model_scope,\n",
    "                                            checkpoint_exclude_scopes, ignore_missing_vars,\n",
    "                                            name_remap={'/kernel': '/weights', '/bias': '/biases'})\n",
    "\n",
    "# couldn't find better way to pass params from input_fn to model_fn\n",
    "# some tensors used by model_fn must be created in input_fn to ensure they are in the same graph\n",
    "# but when we put these tensors to labels's dict, the replicate_model_fn will split them into each GPU\n",
    "# the problem is that they shouldn't be splited\n",
    "global_anchor_info = dict()\n",
    "\n",
    "def input_pipeline(dataset_pattern='train-*', is_training=True, batch_size=batch_size):\n",
    "    def input_fn():\n",
    "        out_shape = [train_image_size] * 2\n",
    "        anchor_creator = anchor_manipulator.AnchorCreator(out_shape,\n",
    "                                                    layers_shapes = [(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)],\n",
    "                                                    anchor_scales = [(0.1,), (0.2,), (0.375,), (0.55,), (0.725,), (0.9,)],\n",
    "                                                    extra_anchor_scales = [(0.1414,), (0.2739,), (0.4541,), (0.6315,), (0.8078,), (0.9836,)],\n",
    "                                                    anchor_ratios = [(1., 2., .5), (1., 2., 3., .5, 0.3333), (1., 2., 3., .5, 0.3333), (1., 2., 3., .5, 0.3333), (1., 2., .5), (1., 2., .5)],\n",
    "                                                    layer_steps = [8, 16, 32, 64, 100, 300])\n",
    "        all_anchors, all_num_anchors_depth, all_num_anchors_spatial = anchor_creator.get_all_anchors()\n",
    "\n",
    "        num_anchors_per_layer = []\n",
    "        for ind in range(len(all_anchors)):\n",
    "            num_anchors_per_layer.append(all_num_anchors_depth[ind] * all_num_anchors_spatial[ind])\n",
    "\n",
    "        anchor_encoder_decoder = anchor_manipulator.AnchorEncoder(allowed_borders = [1.0] * 6,\n",
    "                                                            positive_threshold = match_threshold,\n",
    "                                                            ignore_threshold = neg_threshold,\n",
    "                                                            prior_scaling=[0.1, 0.1, 0.2, 0.2])\n",
    "\n",
    "        image_preprocessing_fn = lambda image_, labels_, bboxes_ : ssd_preprocessing.preprocess_image(image_, labels_, bboxes_, out_shape, is_training=is_training, data_format=data_format, output_rgb=False)\n",
    "        anchor_encoder_fn = lambda glabels_, gbboxes_: anchor_encoder_decoder.encode_all_anchors(glabels_, gbboxes_, all_anchors, all_num_anchors_depth, all_num_anchors_spatial)\n",
    "\n",
    "        image, _, shape, loc_targets, cls_targets, match_scores = dataset_common.slim_get_batch(num_classes,\n",
    "                                                                                batch_size,\n",
    "                                                                                ('train' if is_training else 'val'),\n",
    "                                                                                os.path.join(data_dir, dataset_pattern),\n",
    "                                                                                num_readers,\n",
    "                                                                                num_preprocessing_threads,\n",
    "                                                                                image_preprocessing_fn,\n",
    "                                                                                anchor_encoder_fn,\n",
    "                                                                                num_epochs=train_epochs,\n",
    "                                                                                is_training=is_training)\n",
    "        global global_anchor_info\n",
    "        global_anchor_info = {'decode_fn': lambda pred : anchor_encoder_decoder.decode_all_anchors(pred, num_anchors_per_layer),\n",
    "                            'num_anchors_per_layer': num_anchors_per_layer,\n",
    "                            'all_num_anchors_depth': all_num_anchors_depth }\n",
    "\n",
    "        return image, {'shape': shape, 'loc_targets': loc_targets, 'cls_targets': cls_targets, 'match_scores': match_scores}\n",
    "    return input_fn\n",
    "\n",
    "def modified_smooth_l1(bbox_pred, bbox_targets, bbox_inside_weights=1., bbox_outside_weights=1., sigma=1.):\n",
    "    \"\"\"\n",
    "        ResultLoss = outside_weights * SmoothL1(inside_weights * (bbox_pred - bbox_targets))\n",
    "        SmoothL1(x) = 0.5 * (sigma * x)^2,    if |x| < 1 / sigma^2\n",
    "                      |x| - 0.5 / sigma^2,    otherwise\n",
    "    \"\"\"\n",
    "    with tf.name_scope('smooth_l1', [bbox_pred, bbox_targets]):\n",
    "        sigma2 = sigma * sigma\n",
    "\n",
    "        inside_mul = tf.multiply(bbox_inside_weights, tf.subtract(bbox_pred, bbox_targets))\n",
    "\n",
    "        smooth_l1_sign = tf.cast(tf.less(tf.abs(inside_mul), 1.0 / sigma2), tf.float32)\n",
    "        smooth_l1_option1 = tf.multiply(tf.multiply(inside_mul, inside_mul), 0.5 * sigma2)\n",
    "        smooth_l1_option2 = tf.subtract(tf.abs(inside_mul), 0.5 / sigma2)\n",
    "        smooth_l1_result = tf.add(tf.multiply(smooth_l1_option1, smooth_l1_sign),\n",
    "                                  tf.multiply(smooth_l1_option2, tf.abs(tf.subtract(smooth_l1_sign, 1.0))))\n",
    "\n",
    "        outside_mul = tf.multiply(bbox_outside_weights, smooth_l1_result)\n",
    "\n",
    "        return outside_mul\n",
    "\n",
    "\n",
    "# from scipy.misc import imread, imsave, imshow, imresize\n",
    "# import numpy as np\n",
    "# from utility import draw_toolbox\n",
    "\n",
    "# def save_image_with_bbox(image, labels_, scores_, bboxes_):\n",
    "#     if not hasattr(save_image_with_bbox, \"counter\"):\n",
    "#         save_image_with_bbox.counter = 0  # it doesn't exist yet, so initialize it\n",
    "#     save_image_with_bbox.counter += 1\n",
    "\n",
    "#     img_to_draw = np.copy(image)\n",
    "\n",
    "#     img_to_draw = draw_toolbox.bboxes_draw_on_img(img_to_draw, labels_, scores_, bboxes_, thickness=2)\n",
    "#     imsave(os.path.join('./debug/{}.jpg').format(save_image_with_bbox.counter), img_to_draw)\n",
    "#     return save_image_with_bbox.counter\n",
    "\n",
    "def ssd_model_fn(features, labels, mode, params):\n",
    "    \"\"\"model_fn for SSD to be used with our Estimator.\"\"\"\n",
    "    shape = labels['shape']\n",
    "    loc_targets = labels['loc_targets']\n",
    "    cls_targets = labels['cls_targets']\n",
    "    match_scores = labels['match_scores']\n",
    "\n",
    "    global global_anchor_info\n",
    "    decode_fn = global_anchor_info['decode_fn']\n",
    "    num_anchors_per_layer = global_anchor_info['num_anchors_per_layer']\n",
    "    all_num_anchors_depth = global_anchor_info['all_num_anchors_depth']\n",
    "\n",
    "    # bboxes_pred = decode_fn(loc_targets[0])\n",
    "    # bboxes_pred = [tf.reshape(preds, [-1, 4]) for preds in bboxes_pred]\n",
    "    # bboxes_pred = tf.concat(bboxes_pred, axis=0)\n",
    "    # save_image_op = tf.py_func(save_image_with_bbox,\n",
    "    #                         [ssd_preprocessing.unwhiten_image(features[0]),\n",
    "    #                         tf.clip_by_value(cls_targets[0], 0, tf.int64.max),\n",
    "    #                         match_scores[0],\n",
    "    #                         bboxes_pred],\n",
    "    #                         tf.int64, stateful=True)\n",
    "    # with tf.control_dependencies([save_image_op]):\n",
    "\n",
    "    #print(all_num_anchors_depth)\n",
    "    with tf.variable_scope(params['model_scope'], default_name=None, values=[features], reuse=tf.AUTO_REUSE):\n",
    "        backbone = ssd_net.VGG16Backbone(params['data_format'])\n",
    "        feature_layers = backbone.forward(features, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "        #print(feature_layers)\n",
    "        location_pred, cls_pred = ssd_net.multibox_head(feature_layers, params['num_classes'], all_num_anchors_depth, data_format=params['data_format'])\n",
    "\n",
    "        if params['data_format'] == 'channels_first':\n",
    "            cls_pred = [tf.transpose(pred, [0, 2, 3, 1]) for pred in cls_pred]\n",
    "            location_pred = [tf.transpose(pred, [0, 2, 3, 1]) for pred in location_pred]\n",
    "\n",
    "        cls_pred = [tf.reshape(pred, [tf.shape(features)[0], -1, params['num_classes']]) for pred in cls_pred]\n",
    "        location_pred = [tf.reshape(pred, [tf.shape(features)[0], -1, 4]) for pred in location_pred]\n",
    "\n",
    "        cls_pred = tf.concat(cls_pred, axis=1)\n",
    "        location_pred = tf.concat(location_pred, axis=1)\n",
    "\n",
    "        cls_pred = tf.reshape(cls_pred, [-1, params['num_classes']])\n",
    "        location_pred = tf.reshape(location_pred, [-1, 4])\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        with tf.control_dependencies([cls_pred, location_pred]):\n",
    "            with tf.name_scope('post_forward'):\n",
    "                #bboxes_pred = decode_fn(location_pred)\n",
    "                bboxes_pred = tf.map_fn(lambda _preds : decode_fn(_preds),\n",
    "                                        tf.reshape(location_pred, [tf.shape(features)[0], -1, 4]),\n",
    "                                        dtype=[tf.float32] * len(num_anchors_per_layer), back_prop=False)\n",
    "                #cls_targets = tf.Print(cls_targets, [tf.shape(bboxes_pred[0]),tf.shape(bboxes_pred[1]),tf.shape(bboxes_pred[2]),tf.shape(bboxes_pred[3])])\n",
    "                bboxes_pred = [tf.reshape(preds, [-1, 4]) for preds in bboxes_pred]\n",
    "                bboxes_pred = tf.concat(bboxes_pred, axis=0)\n",
    "\n",
    "                flaten_cls_targets = tf.reshape(cls_targets, [-1])\n",
    "                flaten_match_scores = tf.reshape(match_scores, [-1])\n",
    "                flaten_loc_targets = tf.reshape(loc_targets, [-1, 4])\n",
    "\n",
    "                # each positive examples has one label\n",
    "                positive_mask = flaten_cls_targets > 0\n",
    "                n_positives = tf.count_nonzero(positive_mask)\n",
    "\n",
    "                batch_n_positives = tf.count_nonzero(cls_targets, -1)\n",
    "\n",
    "                batch_negtive_mask = tf.equal(cls_targets, 0)#tf.logical_and(tf.equal(cls_targets, 0), match_scores > 0.)\n",
    "                batch_n_negtives = tf.count_nonzero(batch_negtive_mask, -1)\n",
    "\n",
    "                batch_n_neg_select = tf.cast(params['negative_ratio'] * tf.cast(batch_n_positives, tf.float32), tf.int32)\n",
    "                batch_n_neg_select = tf.minimum(batch_n_neg_select, tf.cast(batch_n_negtives, tf.int32))\n",
    "\n",
    "                # hard negative mining for classification\n",
    "                predictions_for_bg = tf.nn.softmax(tf.reshape(cls_pred, [tf.shape(features)[0], -1, params['num_classes']]))[:, :, 0]\n",
    "                prob_for_negtives = tf.where(batch_negtive_mask,\n",
    "                                       0. - predictions_for_bg,\n",
    "                                       # ignore all the positives\n",
    "                                       0. - tf.ones_like(predictions_for_bg))\n",
    "                topk_prob_for_bg, _ = tf.nn.top_k(prob_for_negtives, k=tf.shape(prob_for_negtives)[1])\n",
    "                score_at_k = tf.gather_nd(topk_prob_for_bg, tf.stack([tf.range(tf.shape(features)[0]), batch_n_neg_select - 1], axis=-1))\n",
    "\n",
    "                selected_neg_mask = prob_for_negtives >= tf.expand_dims(score_at_k, axis=-1)\n",
    "\n",
    "                # include both selected negtive and all positive examples\n",
    "                final_mask = tf.stop_gradient(tf.logical_or(tf.reshape(tf.logical_and(batch_negtive_mask, selected_neg_mask), [-1]), positive_mask))\n",
    "                total_examples = tf.count_nonzero(final_mask)\n",
    "\n",
    "                cls_pred = tf.boolean_mask(cls_pred, final_mask)\n",
    "                location_pred = tf.boolean_mask(location_pred, tf.stop_gradient(positive_mask))\n",
    "                flaten_cls_targets = tf.boolean_mask(tf.clip_by_value(flaten_cls_targets, 0, params['num_classes']), final_mask)\n",
    "                flaten_loc_targets = tf.stop_gradient(tf.boolean_mask(flaten_loc_targets, positive_mask))\n",
    "\n",
    "                predictions = {\n",
    "                            'classes': tf.argmax(cls_pred, axis=-1),\n",
    "                            'probabilities': tf.reduce_max(tf.nn.softmax(cls_pred, name='softmax_tensor'), axis=-1),\n",
    "                            'loc_predict': bboxes_pred }\n",
    "\n",
    "                cls_accuracy = tf.metrics.accuracy(flaten_cls_targets, predictions['classes'])\n",
    "                metrics = {'cls_accuracy': cls_accuracy}\n",
    "\n",
    "                # Create a tensor named train_accuracy for logging purposes.\n",
    "                tf.identity(cls_accuracy[1], name='cls_accuracy')\n",
    "                tf.summary.scalar('cls_accuracy', cls_accuracy[1])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate loss, which includes softmax cross entropy and L2 regularization.\n",
    "    #cross_entropy = tf.cond(n_positives > 0, lambda: tf.losses.sparse_softmax_cross_entropy(labels=flaten_cls_targets, logits=cls_pred), lambda: 0.)# * (params['negative_ratio'] + 1.)\n",
    "    #flaten_cls_targets=tf.Print(flaten_cls_targets, [flaten_loc_targets],summarize=50000)\n",
    "    cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=flaten_cls_targets, logits=cls_pred) * (params['negative_ratio'] + 1.)\n",
    "    # Create a tensor named cross_entropy for logging purposes.\n",
    "    tf.identity(cross_entropy, name='cross_entropy_loss')\n",
    "    tf.summary.scalar('cross_entropy_loss', cross_entropy)\n",
    "\n",
    "    #loc_loss = tf.cond(n_positives > 0, lambda: modified_smooth_l1(location_pred, tf.stop_gradient(flaten_loc_targets), sigma=1.), lambda: tf.zeros_like(location_pred))\n",
    "    loc_loss = modified_smooth_l1(location_pred, flaten_loc_targets, sigma=1.)\n",
    "    #loc_loss = modified_smooth_l1(location_pred, tf.stop_gradient(gtargets))\n",
    "    loc_loss = tf.reduce_mean(tf.reduce_sum(loc_loss, axis=-1), name='location_loss')\n",
    "    tf.summary.scalar('location_loss', loc_loss)\n",
    "    tf.losses.add_loss(loc_loss)\n",
    "\n",
    "    l2_loss_vars = []\n",
    "    for trainable_var in tf.trainable_variables():\n",
    "        if '_bn' not in trainable_var.name:\n",
    "            if 'conv4_3_scale' not in trainable_var.name:\n",
    "                l2_loss_vars.append(tf.nn.l2_loss(trainable_var))\n",
    "            else:\n",
    "                l2_loss_vars.append(tf.nn.l2_loss(trainable_var) * 0.1)\n",
    "    # Add weight decay to the loss. We exclude the batch norm variables because\n",
    "    # doing so leads to a small improvement in accuracy.\n",
    "    total_loss = tf.add(cross_entropy + loc_loss, tf.multiply(params['weight_decay'], tf.add_n(l2_loss_vars), name='l2_loss'), name='total_loss')\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "        lr_values = [params['learning_rate'] * decay for decay in params['lr_decay_factors']]\n",
    "        learning_rate = tf.train.piecewise_constant(tf.cast(global_step, tf.int32),\n",
    "                                                    [int(_) for _ in params['decay_boundaries']],\n",
    "                                                    lr_values)\n",
    "        truncated_learning_rate = tf.maximum(learning_rate, tf.constant(params['end_learning_rate'], dtype=learning_rate.dtype), name='learning_rate')\n",
    "        # Create a tensor named learning_rate for logging purposes.\n",
    "        tf.summary.scalar('learning_rate', truncated_learning_rate)\n",
    "\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate=truncated_learning_rate,\n",
    "                                                momentum=params['momentum'])\n",
    "        optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n",
    "\n",
    "        # Batch norm requires update_ops to be added as a train_op dependency.\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(total_loss, global_step)\n",
    "    else:\n",
    "        train_op = None\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "                              mode=mode,\n",
    "                              predictions=predictions,\n",
    "                              loss=total_loss,\n",
    "                              train_op=train_op,\n",
    "                              eval_metric_ops=metrics,\n",
    "                              scaffold=tf.train.Scaffold(init_fn=get_init_fn()))\n",
    "\n",
    "def parse_comma_list(args):\n",
    "    return [float(s.strip()) for s in args.split(',')]\n",
    "\n",
    "def main():\n",
    "    # Using the Winograd non-fused algorithms provides a small performance boost.\n",
    "    os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'\n",
    "\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False, intra_op_parallelism_threads=num_cpu_threads, inter_op_parallelism_threads=num_cpu_threads, gpu_options=gpu_options)\n",
    "\n",
    "    num_gpus = validate_batch_size_for_multi_gpu(batch_size)\n",
    "\n",
    "    # Set up a RunConfig to only save checkpoints once per training cycle.\n",
    "    run_config = tf.estimator.RunConfig().replace(\n",
    "                                        save_checkpoints_secs=save_checkpoints_secs).replace(\n",
    "                                        save_checkpoints_steps=None).replace(\n",
    "                                        save_summary_steps=save_summary_steps).replace(\n",
    "                                        keep_checkpoint_max=5).replace(\n",
    "                                        tf_random_seed=tf_random_seed).replace(\n",
    "                                        log_step_count_steps=log_every_n_steps).replace(\n",
    "                                        session_config=config)\n",
    "\n",
    "    replicate_ssd_model_fn = tf.contrib.estimator.replicate_model_fn(ssd_model_fn, loss_reduction=tf.losses.Reduction.MEAN)\n",
    "    ssd_detector = tf.estimator.Estimator(\n",
    "        model_fn=replicate_ssd_model_fn, model_dir=model_dir, config=run_config,\n",
    "        params={\n",
    "            'num_gpus': num_gpus,\n",
    "            'data_format': data_format,\n",
    "            'batch_size': batch_size,\n",
    "            'model_scope': model_scope,\n",
    "            'num_classes': num_classes,\n",
    "            'negative_ratio': negative_ratio,\n",
    "            'match_threshold': match_threshold,\n",
    "            'neg_threshold': neg_threshold,\n",
    "            'weight_decay': weight_decay,\n",
    "            'momentum': momentum,\n",
    "            'learning_rate': learning_rate,\n",
    "            'end_learning_rate':end_learning_rate,\n",
    "            'decay_boundaries': parse_comma_list(decay_boundaries),\n",
    "            'lr_decay_factors': parse_comma_list(lr_decay_factors),\n",
    "        })\n",
    "    tensors_to_log = {\n",
    "        'lr': 'learning_rate',\n",
    "        'ce': 'cross_entropy_loss',\n",
    "        'loc': 'location_loss',\n",
    "        'loss': 'total_loss',\n",
    "        'l2': 'l2_loss',\n",
    "        'acc': 'post_forward/cls_accuracy',\n",
    "    }\n",
    "    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=log_every_n_steps,\n",
    "                                            formatter=lambda dicts: (', '.join(['%s=%.6f' % (k, v) for k, v in dicts.items()])))\n",
    "\n",
    "    #hook = tf.train.ProfilerHook(save_steps=50, output_dir='.', show_memory=True)\n",
    "    print('Starting a training cycle.')\n",
    "    ssd_detector.train(input_fn=input_pipeline(dataset_pattern='train-*', is_training=True, batch_size=batch_size),\n",
    "                    hooks=[logging_hook], max_steps=max_number_of_steps)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tf.train.latest_checkpoint(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
