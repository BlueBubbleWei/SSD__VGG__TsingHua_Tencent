{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiyumei/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io \n",
    "import os\n",
    "import pylab as pl\n",
    "import random\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import anno_func \n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/Data/weiyumei/deeplearning/finalwork/dataset/data/test/ids.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-951b6cd055da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfiledir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATADIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/annotations.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 每张图片名称所关联的id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATADIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/test/ids.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0manns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiledir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# print('anns',anns['types'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/Data/weiyumei/deeplearning/finalwork/dataset/data/test/ids.txt'"
     ]
    }
   ],
   "source": [
    "# 获取数据集\n",
    "current=os.getcwd().split('finalwork')[0]\n",
    "DATADIR = os.path.join(current,'dataset/data')\n",
    "IMG_PATH=DATADIR+'/test'\n",
    "MARK_PATH=DATADIR+'/marks' \n",
    "# 位置标记文件\n",
    "filedir=DATADIR+'/annotations.json'\n",
    "# 每张图片名称所关联的id\n",
    "ids=open(DATADIR+'/test/ids.txt').read().splitlines()\n",
    "anns=json.loads(open(filedir).read())\n",
    "# print('anns',anns['types'])\n",
    "# 为类别生成数字编号\n",
    "targets=anns['types']\n",
    "target_classes=dict()\n",
    "for i,name in enumerate(targets):\n",
    "    target_classes[name]=str(i)\n",
    "# print('target_classes',target_classes)\n",
    "\n",
    "def get_img_and_imgNum(test_img_path):\n",
    "    '''获取文件夹中的图片和图片的数字'''\n",
    "    imgs_list=[]\n",
    "    labels_list=[]\n",
    "    for path in test_img_path[:10]:\n",
    "        try:\n",
    "            img=io.imread(path)\n",
    "            imgs_list.append(img)\n",
    "            num_labels=get_num(path)\n",
    "            labels_list.append(num_labels)\n",
    "            if len(imgs_list) % 100 == 0:\n",
    "                print(\"Processing{}/{}\".format(len(imgs_list),len(test_img_path)))\n",
    "        except(IOError,OSError):\n",
    "            print('missed:{}'.format(path))\n",
    "            pass\n",
    "    return imgs_list,labels_list\n",
    "\n",
    "def get_num(img_path):  \n",
    "    '''根据图片的名字截取后面的数字'''\n",
    "    return str(img_path.split('/')[-1].split('.')[0])\n",
    "\n",
    "def load_labels(labels):\n",
    "    '''根据图片名字的数字将交通标志的位置标到图片上'''\n",
    "    img_labels=[]\n",
    "    for i in range(len(labels)):\n",
    "        imgid= labels[i]\n",
    "        imgdata = anno_func.load_img(anns, datadir, imgid)\n",
    "        imgdata_draw = anno_func.draw_all(anns, datadir, imgid, imgdata)\n",
    "        img_labels.append(imgdata_draw)\n",
    "    return img_labels\n",
    "\n",
    "def get_mark_class(MARK_PATH=MARK_PATH):\n",
    "    '''获取label下的所有图片所对应的类别字典'''\n",
    "    mark_img_path=glob.glob(MARK_PATH+'/pad-all'+\"/*.png\")\n",
    "    count=1\n",
    "    class_dict=dict()\n",
    "    with open(MARK_PATH+'/genlist.txt') as mark_text:\n",
    "        line=mark_text.readline()\n",
    "        while line:\n",
    "            if count % 2 != 0:#奇数为图片位置，偶数为图片的类别\n",
    "                name=line.split('/')[-1].rstrip('\\n')\n",
    "            else:\n",
    "                value=line.rstrip('\\n')\n",
    "                class_dict[name]=value\n",
    "                name=[]\n",
    "                value=[]\n",
    "            line=mark_text.readline()\n",
    "            count+=1\n",
    "    return class_dict\n",
    "\n",
    "def get_label_path(lable_text,MARK_PATH=MARK_PATH):  \n",
    "    '''根据label的名称获取label的完整路径'''\n",
    "    print(lable_text)\n",
    "    if lable_class in targets:\n",
    "        print('在的')\n",
    "    lable_text=lable_text+'.png'\n",
    "    if mark_class[lable_text]:\n",
    "#     if lable_text in mark_class.keys():\n",
    "        mark_img_path=MARK_PATH+'/pad-all'+'/'+lable_text+'.png'\n",
    "        marked_class=mark_class[lable_text]\n",
    "    mark_img_path=MARK_PATH+'/pad-all'+'/*.png'\n",
    "    mark_img_path=glob.glob(mark_img_path)\n",
    "    marks=[ get_num(mark) for mark in mark_img_path]\n",
    "    if lable_text in marks:        \n",
    "        mark_img_path=MARK_PATH+'/pad-all'+'/'+lable_text+'.png'\n",
    "    else:\n",
    "        print(lable_text+'is not existed')\n",
    "    return mark_img_path,marked_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 获取test下的所有图片路径\n",
    "test_img_path=glob.glob(IMG_PATH+\"/*.jpg\")\n",
    "\n",
    "# 随机打乱数据集\n",
    "np.random.shuffle(test_img_path)\n",
    "\n",
    "# 测试集的图片和图片的id\n",
    "imgs,labels_id=get_img_and_imgNum(test_img_path)\n",
    "\n",
    "#读取mark的图片名称所对应的类别字典\n",
    "mark_class=get_mark_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "reload(anno_func) \n",
    "count=0\n",
    "for i in range(len(labels_id)):\n",
    "#     print(i)\n",
    "    if count <= 5:\n",
    "        imgid= labels_id[i]\n",
    "        print('imgid',imgid)\n",
    "#         load_img  anns 标注信息集, DATADIR 文件地址, imgid 图片id编号，返回归一化的bgr图片\n",
    "        imgdata = anno_func.load_img(anns, DATADIR, imgid)\n",
    "#        draw_all： anns 标注信息集, DATADIR 文件地址, imgid 图片id编号, imgdata 图片信息\n",
    "        imgdata_draw,mask_ellipse,img = anno_func.draw_all(anns, DATADIR, imgid, imgdata)\n",
    "\n",
    "        break\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(filename)\n",
    "# plt.figure(figsize=(20,20))\n",
    "# plt.imshow(imgdata_draw)\n",
    "# plt.figure(figsize=(20,20))\n",
    "# plt.imshow(mask_ellipse)\n",
    "from imp import reload\n",
    "reload(anno_func) \n",
    "def get_img_info(img):\n",
    "    imgid=img.split('.')[0]\n",
    "    #         load_img  anns 标注信息集, DATADIR 文件地址, imgid 图片id编号，返回归一化的bgr图片\n",
    "    imgdata = anno_func.load_img(anns, DATADIR, imgid)\n",
    "    #        draw_all： anns 标注信息集, DATADIR 文件地址, imgid 图片id编号, imgdata 图片信息\n",
    "    imgdata_draw,mask_ellipse,img = anno_func.draw_all(anns, DATADIR, imgid, imgdata)\n",
    "    img_info=img['objects']\n",
    "    label_classes=[]\n",
    "    label_text=[]\n",
    "    bbox_list=[]\n",
    "    ymin = []\n",
    "    xmin = []\n",
    "    ymax = []\n",
    "    xmax = []\n",
    "    for obj in range(len(img_info)):\n",
    "        label_text.append(img_info[obj]['category'].encode())\n",
    "        bbox=img_info[obj]['bbox']\n",
    "        assert len(bbox) == 4\n",
    "        bbox_list.append([bbox['xmin'],bbox['ymin'],bbox['xmax'],bbox['ymax']])\n",
    "#         xmin.append(bbox['xmin'])\n",
    "#         ymin.append(bbox['ymin'])\n",
    "#         xmax.append(bbox['xmax'])\n",
    "#         ymax.append(bbox['ymax'])\n",
    "        label_classes.append(int(target_classes[img_info[obj]['category']]))\n",
    "    return bbox_list,label_classes,label_text\n",
    "print(get_img_info('75322.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不知道什么用途\n",
    "RANDOM_SEED = 180428\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"将int64类型加入到实例原型的装饰器\"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"将float类型加入到实例原型的装饰器\"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _bytes_list_feature(value):\n",
    "    \"\"\"将二进制列表类型加入到实例原型的装饰器\"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"将二进制类型加入到实例原型的装饰器\"\"\"\n",
    "    if isinstance(value, six.string_types):\n",
    "        value = six.binary_type(value, encoding='utf-8')\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _convert_to_example(filename,image_name, image_buffer,bboxes,labels, labels_text,\n",
    "                        height, width):\n",
    "    \"\"\"\n",
    "    构建一个示例proto作为示例。\n",
    "    args：\n",
    "     filename：string，图像文件的路径，例如'/path/to/example.JPG'\n",
    "     image_buffer：字符串，RGB图像的JPEG编码\n",
    "     bboxes：每个图像的边界框列表\n",
    "     labels：边界框的标签列表\n",
    "     labels_text：边界框的标签名称列表\n",
    "     difficult：整数列表表明该边界框的难度\n",
    "     truncated：整数列表表示该边界框的截断\n",
    "     height：整数，图像高度（以像素为单位）\n",
    "     width：整数，图像宽度（以像素为单位）\n",
    "     Returns：\n",
    "     Example proto    \n",
    "    \"\"\"\n",
    "    ymin = []\n",
    "    xmin = []\n",
    "    ymax = []\n",
    "    xmax = []\n",
    "    for b in bboxes:\n",
    "        assert len(b) == 4\n",
    "        # pylint: disable=expression-not-assigned\n",
    "        [l.append(point) for l, point in zip([ymin, xmin, ymax, xmax], b)]\n",
    "    channels = 3\n",
    "    image_format = 'JPEG'\n",
    "#     labels_text=labels_text.encode()\n",
    "#     循环获取信息，加入list\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image/height': _int64_feature(height),\n",
    "            'image/width': _int64_feature(width),\n",
    "            'image/channels': _int64_feature(channels),\n",
    "            'image/shape': _int64_feature([height, width, channels]),\n",
    "            'image/object/bbox/xmin': _float_feature(xmin),\n",
    "            'image/object/bbox/xmax': _float_feature(xmax),\n",
    "            'image/object/bbox/ymin': _float_feature(ymin),\n",
    "            'image/object/bbox/ymax': _float_feature(ymax),\n",
    "            'image/object/bbox/label': _int64_feature(labels),\n",
    "            'image/object/bbox/label_text': _bytes_list_feature(labels_text),\n",
    "            'image/format': _bytes_feature(image_format),\n",
    "            'image/filename': _bytes_feature(image_name.encode('utf8')),\n",
    "            'image/encoded': _bytes_feature(image_buffer)}))\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCoder(object):\n",
    "    \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # sess 回调所有的图片\n",
    "        self._sess = tf.Session()\n",
    "\n",
    "        # 将png转成jpg.\n",
    "        self._png_data = tf.placeholder(dtype=tf.string)\n",
    "        image = tf.image.decode_png(self._png_data, channels=3)\n",
    "        self._png_to_jpeg = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "        # 将CMYK JPEG 转成 RGB JPEG d\n",
    "        self._cmyk_data = tf.placeholder(dtype=tf.string)\n",
    "        image = tf.image.decode_jpeg(self._cmyk_data, channels=0)\n",
    "        self._cmyk_to_rgb = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "        # 解码RGB\n",
    "        self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n",
    "        self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n",
    "\n",
    "    def png_to_jpeg(self, image_data):\n",
    "        return self._sess.run(self._png_to_jpeg,\n",
    "                          feed_dict={self._png_data: image_data})\n",
    "\n",
    "    def cmyk_to_rgb(self, image_data):\n",
    "        return self._sess.run(self._cmyk_to_rgb,\n",
    "                          feed_dict={self._cmyk_data: image_data})\n",
    "\n",
    "    def decode_jpeg(self, image_data):\n",
    "        image = self._sess.run(self._decode_jpeg,\n",
    "                               feed_dict={self._decode_jpeg_data: image_data})\n",
    "        assert len(image.shape) == 3\n",
    "        assert image.shape[2] == 3\n",
    "        return image\n",
    "\n",
    "\n",
    "def _process_image(filename, coder):\n",
    "    \"\"\"处理单张图片\n",
    "    Args:\n",
    "    filename: '/path/to/example.JPG'.\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "    Returns:\n",
    "    image_buffer: string, JPEG encoding of RGB image.\n",
    "    height: integer, image height in pixels.\n",
    "    width: integer, image width in pixels.\n",
    "    \"\"\"\n",
    "    # 读取图片.\n",
    "    with tf.gfile.FastGFile(filename, 'rb') as f:\n",
    "        image_data = f.read()\n",
    "\n",
    "    # 解码RGB JPEG.\n",
    "    image = coder.decode_jpeg(image_data)\n",
    "\n",
    "    # 转成 RGB\n",
    "    assert len(image.shape) == 3\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "#     print('image.shape[2]:',image.shape[2])\n",
    "    assert image.shape[2] == 3\n",
    "\n",
    "    return image_data, height, width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_image_files_batch(coder, thread_index, ranges, name, directory, all_records, num_shards):\n",
    "    \"\"\"Processes and saves list of images as TFRecord in 1 thread.在单线程中处理并保存为 TFRecord 图片列表\n",
    "    Args:\n",
    "    coder: ImageCoder实例提供TensorFlow图像编码工具。\n",
    "    thread_index: integer, unique batch to run index is within [0, len(ranges)).\n",
    "    ranges: 指定要并行分析的每个批次范围的整数对列表。\n",
    "    name: string,指定数据集的唯一标识符\n",
    "    directory: string; 所有数据的路径\n",
    "    all_records: 字符串元组列表; 每个元组的第一个是记录的子目录，第二个是图像文件名。\n",
    "    num_shards: num_shards：此数据集的整数分片数。\n",
    "    \"\"\"\n",
    "    # Each thread produces N shards where N = int(num_shards / num_threads).\n",
    "    # For instance, if num_shards = 128, and the num_threads = 2, then the first\n",
    "    # thread would produce shards [0, 64).\n",
    "    num_threads = len(ranges)\n",
    "    assert not num_shards % num_threads\n",
    "    num_shards_per_batch = int(num_shards / num_threads)\n",
    "\n",
    "    shard_ranges = np.linspace(ranges[thread_index][0],\n",
    "                             ranges[thread_index][1],\n",
    "                             num_shards_per_batch + 1).astype(int)\n",
    "    num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n",
    "\n",
    "    counter = 0\n",
    "    for s in range(num_shards_per_batch):\n",
    "        #生成文件名的分片版本, e.g. 'train-00002-of-00010'\n",
    "        shard = thread_index * num_shards_per_batch + s\n",
    "        output_filename = '%s-%.5d-of-%.5d' % (name, shard, num_shards)\n",
    "        output_file = os.path.join(output_directory, output_filename)\n",
    "        with open(output_file, 'wb'):\n",
    "            writer = tf.python_io.TFRecordWriter(output_file)\n",
    "        \n",
    "\n",
    "        shard_counter = 0\n",
    "        files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n",
    "        for i in files_in_shard:\n",
    "            cur_record = all_records[i]\n",
    "            filename = os.path.join(directory, cur_record[0],  cur_record[1])\n",
    "    #         print('filename',filename)\n",
    "\n",
    "    #         print('cur_record[1]',cur_record[1]) 34603.jpg\n",
    "    #         bboxes, labels, labels_text, difficult, truncated = _find_image_bounding_boxes(directory, cur_record)\n",
    "\n",
    "            image_buffer, height, width = _process_image(filename, coder)\n",
    "            bboxes,labels,labels_text=get_img_info(cur_record[1])\n",
    "            example = _convert_to_example(filename, cur_record[1], image_buffer, bboxes, labels, labels_text,\n",
    "                                        height, width)\n",
    "            writer.write(example.SerializeToString())\n",
    "            shard_counter += 1\n",
    "            counter += 1\n",
    "\n",
    "            if not counter % 1000:\n",
    "                print('%s [thread %d]: Processed %d of %d images in thread batch.' %\n",
    "                  (datetime.now(), thread_index, counter, num_files_in_thread))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        writer.close()\n",
    "        print('%s [thread %d]: Wrote %d images to %s' %\n",
    "              (datetime.now(), thread_index, shard_counter, output_file))\n",
    "        sys.stdout.flush()\n",
    "        shard_counter = 0\n",
    "    print('%s [thread %d]: Wrote %d images to %d shards.' %\n",
    "        (datetime.now(), thread_index, counter, num_files_in_thread))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_image_files(name, directory, all_records, num_shards):\n",
    "    \"\"\"处理并保存图像列表作为示例protos的TFRecord。\n",
    "    Args:\n",
    "    name: string, unique identifier specifying the data set\n",
    "    directory: string; the path of all datas\n",
    "    all_records:字符串元组列表; 每个元组的第一个是记录的子目录，第二个是图像文件名。 \n",
    "    num_shards: integer number of shards for this data set.\n",
    "    \"\"\"\n",
    "    # Break all images into batches with a [ranges[i][0], ranges[i][1]].\n",
    "    spacing = np.linspace(0, len(all_records),num_threads + 1).astype(np.int)\n",
    "    ranges = []\n",
    "    threads = []\n",
    "    for i in range(len(spacing) - 1):\n",
    "        ranges.append([spacing[i], spacing[i + 1]])\n",
    "\n",
    "    # 为每个批次启动一个线程。\n",
    "    print('Launching %d threads for spacings: %s' % (num_threads, ranges))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # 创建一个监视所有线程何时完成的机制。\n",
    "    coord = tf.train.Coordinator()\n",
    "\n",
    "    # 创建一个基于TensorFlow的通用实用程序，用于转换所有图像编码。\n",
    "    coder = ImageCoder()\n",
    "\n",
    "    threads = []\n",
    "    for thread_index in range(len(ranges)):\n",
    "        args = (coder, thread_index, ranges, name, directory, all_records, num_shards)\n",
    "        t = threading.Thread(target=_process_image_files_batch, args=args)\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    # Wait for all the threads to terminate.\n",
    "    coord.join(threads)\n",
    "    print('%s: Finished writing all %d images in data set.' %\n",
    "        (datetime.now(), len(all_records)))\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_dataset(name, directory, all_splits, num_shards):\n",
    "    \"\"\"处理完整的数据集并将其另存为TFRecord。\n",
    "    Args:\n",
    "    name: string, unique identifier specifying the data set.\n",
    "    directory: string, root path to the data set.\n",
    "    all_splits: list of strings, sub-path to the data set.\n",
    "    num_shards: integer number of shards for this data set.\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    for split in all_splits:\n",
    "        jpeg_file_path = os.path.join(directory, split)\n",
    "        images = tf.gfile.ListDirectory(jpeg_file_path)\n",
    "        jpegs = [im_name for im_name in images if im_name.strip()[-3:]=='jpg']\n",
    "        all_records.extend(list(zip([split] * len(jpegs), jpegs)))\n",
    "        \n",
    "    shuffled_index = list(range(len(all_records)))\n",
    "    random.seed(RANDOM_SEED)\n",
    "    random.shuffle(shuffled_index)\n",
    "    all_records = [all_records[i] for i in shuffled_index]\n",
    "    _process_image_files(name, directory, all_records, num_shards)\n",
    "\n",
    "def parse_comma_list(args):\n",
    "    return [s.strip() for s in args.split(',')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads=4\n",
    "train_shards=8\n",
    "directory=DATADIR\n",
    "test='test'\n",
    "output_directory=DATADIR+'/Tfrecords'\n",
    "# _process_dataset('train',directory,parse_comma_list(test),train_shards)\n",
    "# _process_dataset('val', FLAGS.dataset_directory, parse_comma_list(FLAGS.validation_splits), FLAGS.validation_shards)\n",
    "# _process_dataset('train', FLAGS.dataset_directory, parse_comma_list(FLAGS.train_splits), FLAGS.train_shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换成one_hot编码\n",
    "n_class=len(target_classes)\n",
    "classes=np.array([int(target_classes[i]) for i in target_classes])\n",
    "label = tf.cast(classes, tf.int32)\n",
    "label = tf.one_hot(label,n_class,1,0)\n",
    "sess=tf.Session()\n",
    "print(sess.run(label))\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
